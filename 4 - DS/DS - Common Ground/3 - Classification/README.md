# Chapter 3: Classification

## Theoretical part:

### Introduction

Read in ISLR pages 127-130.

### Logistic Regression:
Read 130-138 in ISLR.


### Naïve Bayes:
Read attached file:  Naïve Bayes Explained.

### LDA:
Read 138-150 in ISLR.

### KNN:
Implement vectorized KNN and compare your solution to the sklearn method.
For the exercise, we took the code from the first exercise in the Stanford CS231 course. Where there is a notebook named  KNN  which contains a TODO function in which theKNN  operation must be completed in  vectorform.
You can read the Knn extension in the preamble in the following link (be careful not to read  the answers;):
https://kevinzakka.github.io/2016/07/13/k-nearest-neighbor/

Read 151-154 in ISLR.

## Practical part:

In this exercise, we will use Iris dataset: https://drive.google.com/drive/folders/1oKUGk5J5ocg0g5PREJF6pEQwdO00Fxd5?usp=sharing.

The data is split to 3 classes: SetosaSilky,  Versicolour,Virginica..

Each record has four properties:

●	Sepal Length.

●	Sepal Width.

●	Petal Length.

●	Petal Width.

You must build a classifier that has maximum precision for an engagement classification for the three categories above.

In your troubleshooting you must include the following steps:

-	Aksploratia of the information.

-	Testing models.

-	Compare the models that were examined.

-	Conclusions.
