{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch Tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ChzhDpPPZwZ1",
        "y0yYyIDi-DVy",
        "maZnGuwo-bEu",
        "ZOMMiUS8-iTA",
        "c592nR1__vsZ",
        "9lWfOt4J_3Va",
        "rWwEpMST_7c6"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "13ee488ac87d4ca08ca65c52007b9a45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_13fb20cbc4ec498cb3647cb8bc5636e6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_db1a520d33ec492cafc7c4bef5ac0b4d",
              "IPY_MODEL_e61e6d62807a4d98aa02ec9efce34385"
            ]
          }
        },
        "13fb20cbc4ec498cb3647cb8bc5636e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "db1a520d33ec492cafc7c4bef5ac0b4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1a1a983a94054905bb11a17b63849a42",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7be10f41d44a494d9f7b505defdddecd"
          }
        },
        "e61e6d62807a4d98aa02ec9efce34385": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c3f755f2031140a58703ca96f2aba0c1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9920512/? [00:01&lt;00:00, 6100506.18it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c622970aa21d4950a22211d471ab0c37"
          }
        },
        "1a1a983a94054905bb11a17b63849a42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7be10f41d44a494d9f7b505defdddecd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c3f755f2031140a58703ca96f2aba0c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c622970aa21d4950a22211d471ab0c37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c6526d53f38f4e18a2f05d10ed235b71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1e316fe196364204a40b6086aa138042",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bf5a42a74d2649819101e76e175be5b0",
              "IPY_MODEL_374216a3626e44b6aaa31635e7e4463f"
            ]
          }
        },
        "1e316fe196364204a40b6086aa138042": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bf5a42a74d2649819101e76e175be5b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c6d6eb302b6641639f9e23d1c85e718b",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_55b895b1eb4540b3b85657182e7b2d3d"
          }
        },
        "374216a3626e44b6aaa31635e7e4463f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e7745844a9d74fd5a9f081921359e78d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/28881 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c719772f047d4b7dafc1d70a5d24b3f7"
          }
        },
        "c6d6eb302b6641639f9e23d1c85e718b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "55b895b1eb4540b3b85657182e7b2d3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e7745844a9d74fd5a9f081921359e78d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c719772f047d4b7dafc1d70a5d24b3f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "058ddde9299f4ad48eb342d6c9ebf8e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_df392a622edf4fddbc3a191df64e0716",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1948a4f92b834db3a2815fa21f42d09e",
              "IPY_MODEL_563eee532e3c42a692c7982427b86b45"
            ]
          }
        },
        "df392a622edf4fddbc3a191df64e0716": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1948a4f92b834db3a2815fa21f42d09e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c623591cb7a14d1eacaedf0e448d0dcb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f7761dd859d44fbbb49e0e42ca1ee8a8"
          }
        },
        "563eee532e3c42a692c7982427b86b45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e22d257c1f9f441c85ac955e45747e94",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1654784/? [00:18&lt;00:00, 251485.57it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3cf21db7920442a9b00e9fc29b080a7f"
          }
        },
        "c623591cb7a14d1eacaedf0e448d0dcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f7761dd859d44fbbb49e0e42ca1ee8a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e22d257c1f9f441c85ac955e45747e94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3cf21db7920442a9b00e9fc29b080a7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c619812fdeb640809c699c56b87198f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_612439a0c2a74fac89324226f1d7ff33",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ba16954260ee49d186433e63b60f3757",
              "IPY_MODEL_905c9c03e2fb4e578b485676729e8a74"
            ]
          }
        },
        "612439a0c2a74fac89324226f1d7ff33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ba16954260ee49d186433e63b60f3757": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8468b21b37584ea6a88794352c548154",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cb166b52b45f40188d4ff158ff1e9ff4"
          }
        },
        "905c9c03e2fb4e578b485676729e8a74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f4aa2f9b38274399b79e1cde38002e5a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/4542 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dd1aadb71d6a4025aa1c3c5ef939a66e"
          }
        },
        "8468b21b37584ea6a88794352c548154": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cb166b52b45f40188d4ff158ff1e9ff4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f4aa2f9b38274399b79e1cde38002e5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dd1aadb71d6a4025aa1c3c5ef939a66e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9-Pf1IcYAV8",
        "colab_type": "text"
      },
      "source": [
        "**Pytorch Tutorial**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkvGRUCaeodt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChzhDpPPZwZ1",
        "colab_type": "text"
      },
      "source": [
        "## Tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Udcl8tCgZ6B1",
        "colab_type": "text"
      },
      "source": [
        "Tensors are the base data structures of PyTorch which are used for building different types of neural networks. They can be considered as the generalization of arrays and matrices; in other words, tensors are N-dimensional matrices or multidimensional arrays.\n",
        "\n",
        "PyTorch tensors are similar to NumPy’s n-dimensional arrays. But unlike ndarrays of numpy, these tensors can be stored on a GPU RAM as well as the CPU RAM, and than to be multiplied efficientlly on the small many cores of the GPU (this is not the case with NumPy arrays). This is a major advantage of using tensors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34hjE_dnjuUE",
        "colab_type": "text"
      },
      "source": [
        "###  Tensor Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVdMHgL5gsuy",
        "colab_type": "text"
      },
      "source": [
        "Tensors can be created by using a list:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gbGK5BifniP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eedfcfb2-e389-4fa1-eb41-32286c0a23f2"
      },
      "source": [
        "x = torch.tensor([1,2,3])\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1, 2, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hS2GJDPThBSg",
        "colab_type": "text"
      },
      "source": [
        "You can specify the data type of the tensor by using the ``dtype`` argument,\n",
        "similarily to numpy, you can check the type of the tensor by using the ``dtype`` attribute:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWP-mViIiNrI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "587b25f3-561b-42d1-e2aa-403478d6964c"
      },
      "source": [
        "x = torch.tensor([1,2,3], dtype = torch.float32)\n",
        "print(x)\n",
        "print(x.dtype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 2., 3.])\n",
            "torch.float32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hx3qL4M8n5eP",
        "colab_type": "text"
      },
      "source": [
        "It's important to note here that one way to evaluate a GPU is by its TFLOPS - the capability of a processor to calculate one trillion floating-point operations per second. These operations rate usually refer to a 32bit floating point and abiously depends on the tensot type. operations on a 64bit floating point will be half the rate and so on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjvJ5IaPkDl-",
        "colab_type": "text"
      },
      "source": [
        "Let’s say we want a matrix of shape 3*3 having all zeros/ones. Take a moment to think – how can we do that using NumPy?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXOFNYdaj4Bd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "b8a76cb4-e03c-406a-8a80-2070761598d4"
      },
      "source": [
        "a = np.zeros((3,3))\n",
        "b = np.ones((3,3))\n",
        "\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "[[1. 1. 1.]\n",
            " [1. 1. 1.]\n",
            " [1. 1. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DY3HOvAOkUjU",
        "colab_type": "text"
      },
      "source": [
        "Similar to NumPy, PyTorch also has the zeros() and ones() function which takes the shape as input and returns a matrix of zeros or ones , respectively, of a specified shape."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxZN_iT4j4FX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "beb93051-b945-40ca-cf69-3595a2c4ef22"
      },
      "source": [
        "a = torch.zeros((3,3))\n",
        "b = torch.ones((3,3))\n",
        "\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8Y-nSZAoqBF",
        "colab_type": "text"
      },
      "source": [
        "The ``random.randn()`` function returns random numbers that follow a standard normal distribution. \n",
        "\n",
        "We can initialize a similar matrix of random numbers using PyTorch:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9syMOW-lj4I_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e384d584-ac9e-4f4f-ee3f-0614d28b066a"
      },
      "source": [
        "a = torch.randn(2,3)\n",
        "\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-1.8783,  0.6180, -0.9610],\n",
            "        [-0.9602, -1.7552,  0.3963]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUMUuLeBDKfa",
        "colab_type": "text"
      },
      "source": [
        "### Tensor Copying"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIej_VuCDP4Y",
        "colab_type": "text"
      },
      "source": [
        "As you will see later in this chapter,\n",
        "most of the tensor operations create a view of the origin tensor.\n",
        "\n",
        "Since it is a room for errors you must notice when you need to create a copy of your origin tensor.\n",
        "\n",
        "Unlike numpy, in torch the syntax is a bit different."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cOUs78lE5eb",
        "colab_type": "text"
      },
      "source": [
        "The function `copy_` copies the tensor given as a parameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKPmKwwmCv2Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "1d2bf780-d0b1-4b50-b2d1-c4412d12cbf6"
      },
      "source": [
        "a = torch.randn(3,3)\n",
        "print(a, \"\\n\")\n",
        "\n",
        "b = torch.empty(3,3)\n",
        "b.copy_(a)\n",
        "print(b, \"\\n\")\n",
        "\n",
        "a[0,0] = 10\n",
        "print(a[0,0], \"\\n\")\n",
        "print(b[0,0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-1.1124, -1.0314, -0.8489],\n",
            "        [-0.1366,  1.1057, -0.9612],\n",
            "        [-0.3910, -0.6203,  0.1014]]) \n",
            "\n",
            "tensor([[-1.1124, -1.0314, -0.8489],\n",
            "        [-0.1366,  1.1057, -0.9612],\n",
            "        [-0.3910, -0.6203,  0.1014]]) \n",
            "\n",
            "tensor(10.) \n",
            "\n",
            "tensor(-1.1124)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bqdJJQWGwcL",
        "colab_type": "text"
      },
      "source": [
        "The function `clone` also copies a tensor.\n",
        "\n",
        "However, unlike `copy_`, this function is recorded in the computation graph. \n",
        "(As you will see later in this tutorial, it means that gradients propagating to the cloned tensor will propagate to the original tensor.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J41DL91zGJHl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "1bb1663d-8bde-4e38-b42e-a58d5b299ff9"
      },
      "source": [
        "a = torch.randn(3,3)\n",
        "print(a, \"\\n\")\n",
        "\n",
        "b = torch.empty(3,3)\n",
        "b = a.clone()\n",
        "print(b, \"\\n\")\n",
        "\n",
        "a[0,0] = 10\n",
        "print(a[0,0], \"\\n\")\n",
        "print(b[0,0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.2498,  0.2671, -0.8300],\n",
            "        [-0.2340,  1.8239, -0.2401],\n",
            "        [-0.1279, -0.4556, -0.4793]]) \n",
            "\n",
            "tensor([[-0.2498,  0.2671, -0.8300],\n",
            "        [-0.2340,  1.8239, -0.2401],\n",
            "        [-0.1279, -0.4556, -0.4793]]) \n",
            "\n",
            "tensor(10.) \n",
            "\n",
            "tensor(-0.2498)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZE0e6D-D0x9t",
        "colab_type": "text"
      },
      "source": [
        "### Shaping and Reshaping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okaAc0As07rF",
        "colab_type": "text"
      },
      "source": [
        "You can get the shape of a tensor using the ``.size()`` method or just the `.shape` attribute."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9Ou2RMu0yOO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "619574a4-c8b0-4103-e992-6cb491224180"
      },
      "source": [
        "a = torch.randn(2,3)\n",
        "\n",
        "print(a.size())\n",
        "print(a.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 3])\n",
            "torch.Size([2, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zUy9uI22miZ",
        "colab_type": "text"
      },
      "source": [
        "We can use the `.view()` function and pass the required shape as a parameter. \n",
        "\n",
        "It will return a tensor with the new shape. \n",
        "\n",
        "Pay attention that the returned tensor isn't a copy of the original tensor, it will share the underling data with the original tensor.\n",
        "\n",
        "Let’s try to convert the above tensor of shape (2,3) to a tensor of shape (6,1):\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbEoYY0D2qPb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "57aecae7-fd06-4b5d-c260-90a555f635dc"
      },
      "source": [
        "b = a.view(6,1)\n",
        "print(b)\n",
        "print(b.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1.0940],\n",
            "        [-0.6838],\n",
            "        [-0.1457],\n",
            "        [ 1.1312],\n",
            "        [-0.1067],\n",
            "        [-0.9723]])\n",
            "torch.Size([6, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HP7r3aoC2qSS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "9db33165-4703-44ea-b1a6-99b85b4e9c2e"
      },
      "source": [
        "a[0][0]=5\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 5.0000],\n",
            "        [-0.6838],\n",
            "        [-0.1457],\n",
            "        [ 1.1312],\n",
            "        [-0.1067],\n",
            "        [-0.9723]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzEu5hhq3ELO",
        "colab_type": "text"
      },
      "source": [
        "If you know you want, for example, 6 rows however, you want torch to conclude the number of columns, you should send -1 as the columns dim argument"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIdpWk8R3dlD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "056904e4-355a-438a-82b8-c2f01d1a346b"
      },
      "source": [
        "a = torch.randn(3,4,5)\n",
        "b = a.view(-1,12)\n",
        "print(b)\n",
        "print(b.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.7113,  0.6297,  0.1232,  0.6469, -0.2065, -0.6196,  0.7400,  2.3763,\n",
            "          1.5697, -0.0928,  1.6582, -0.1015],\n",
            "        [ 0.9270,  0.9450,  1.6292, -0.3656,  0.0709, -0.1493, -0.3180, -0.7879,\n",
            "         -0.0171, -2.2749,  0.6409,  0.0876],\n",
            "        [ 0.0217, -0.2510, -0.1346,  2.2710,  0.4816,  1.2160,  1.4600, -0.1975,\n",
            "         -1.0890, -1.4707,  1.3135, -1.0782],\n",
            "        [ 1.2744, -1.1926, -0.0096, -0.2496, -0.6022, -0.5855, -0.0917, -0.4569,\n",
            "         -1.0288,  0.2488,  0.0895,  1.2220],\n",
            "        [ 0.3659, -0.9173, -0.1654,  0.4994, -0.6953, -0.8574, -0.2142,  0.3011,\n",
            "         -1.0792,  1.5648,  0.7269,  0.8289]])\n",
            "torch.Size([5, 12])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dl8K1RR2IAVh",
        "colab_type": "text"
      },
      "source": [
        "If you have two twnsors with the same amount of elements and you want to make their shape the same you can pass one's shape as a parameter to the `view` function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PD_ddmzuH3BL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "67da7391-702a-4696-8ce8-7b52df525478"
      },
      "source": [
        "a = torch.randn(3,4,5)\n",
        "print(a.size())\n",
        "b = torch.randn(6, 10)\n",
        "print(b.size(), \"\\n\")\n",
        "\n",
        "b = b.view(a.size())\n",
        "print(b.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 4, 5])\n",
            "torch.Size([6, 10]) \n",
            "\n",
            "torch.Size([3, 4, 5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6QZ5OaUIx4e",
        "colab_type": "text"
      },
      "source": [
        "However, you can do it more elegantlly using the `view_as` function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VPj_AWvI-mT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "00150d2d-0c24-432b-c278-08936244b0f3"
      },
      "source": [
        "a = torch.randn(3,4,5)\n",
        "print(a.size())\n",
        "b = torch.randn(6, 10)\n",
        "print(b.size(), \"\\n\")\n",
        "\n",
        "b = b.view_as(a)\n",
        "print(b.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 4, 5])\n",
            "torch.Size([6, 10]) \n",
            "\n",
            "torch.Size([3, 4, 5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4W2-j4da2-rJ",
        "colab_type": "text"
      },
      "source": [
        "You can also use the `torch.reshape` method,\n",
        "however, pay attentaion that torch.reshape may return a copy or a view of the original tensor - `torch.reshape` method will try to share the memory of the returned tensor, but if that complicates things for the torch architecture torch will make a clone of it and will return a new reshaped tensor. Thus you can not count on that to return a view or a copy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkoyXPWYT5ek",
        "colab_type": "text"
      },
      "source": [
        "In order to transpose a 2D tensor, you can use ``torch.t`` as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_f8AKKPaT9Ou",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "68860042-3a7c-487e-ad89-acfa85ce212f"
      },
      "source": [
        "a = torch.randn(2,3)\n",
        "\n",
        "print(a)\n",
        "print(f\"tensor a shape is {a.shape} \\n\")\n",
        "\n",
        "a_t = torch.t(a)\n",
        "print(a_t)\n",
        "print(f\"the transpose of tensor a shape is {a_t.shape} \\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0498,  1.1942, -0.2112],\n",
            "        [ 0.2853,  1.5957, -0.3287]])\n",
            "tensor a shape is torch.Size([2, 3]) \n",
            "\n",
            "tensor([[ 0.0498,  0.2853],\n",
            "        [ 1.1942,  1.5957],\n",
            "        [-0.2112, -0.3287]])\n",
            "the transpose of tensor a shape is torch.Size([3, 2]) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-j1Y7aG1UH5J",
        "colab_type": "text"
      },
      "source": [
        "Pay attention that 0-D and 1-D tensors are returned as is. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obxGtUGjUJGS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "f6b0dd83-3679-4b30-92fb-05fddfe44067"
      },
      "source": [
        "a = torch.randn(5)\n",
        "print(a.shape, \"\\n\")\n",
        "\n",
        "a_t = torch.t(a)\n",
        "print(a_t.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5]) \n",
            "\n",
            "torch.Size([5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASK30QiE1Jh7",
        "colab_type": "text"
      },
      "source": [
        "If you want to transpose a tensor with more than 2 dimensions, you can use the `permute` function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEB798Wf2uxu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "302f3703-e96e-4b71-fed7-b5e471b2011f"
      },
      "source": [
        "a = torch.randn(3, 4, 5)\n",
        "print(a.size())\n",
        "b.copy_(a.permute(2, 0, 1))\n",
        "print(b.size())\n",
        "\n",
        "print(a[1,2,3] == b[3,1,2])\n",
        "print(a[1,2,3] == b[1,2,3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 4, 5])\n",
            "torch.Size([5, 3, 4])\n",
            "tensor(True)\n",
            "tensor(False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyY_of_VtjKr",
        "colab_type": "text"
      },
      "source": [
        "### Mathematical Operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQNGI21FuNrB",
        "colab_type": "text"
      },
      "source": [
        "Let’s now see how we can do mathematical operations using PyTorch on tensors. So, first, let’s initialize two tensors:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8YW3fnztiq7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "5a776bc3-fc3e-4c56-dbb8-285da9b21f80"
      },
      "source": [
        "a = torch.randn(2,3)\n",
        "b = torch.randn(2,3)\n",
        "\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.3121, -0.2046, -1.0139],\n",
            "        [ 0.2884,  0.2794,  1.0529]])\n",
            "tensor([[ 0.8672,  0.2541, -0.3900],\n",
            "        [-0.0240, -0.9956, -0.4692]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEJJRX5QvRm8",
        "colab_type": "text"
      },
      "source": [
        "There are 3 different ways to perform mathematical operations:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWOf2t7Evbzs",
        "colab_type": "text"
      },
      "source": [
        "1. Well known  mathematical operators:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "788AXVMbj4OU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "a588a775-97f0-41b9-878e-28c1c4a7002f"
      },
      "source": [
        "# addition\n",
        "print(a+b, \"\\n\")       # equivalent to: torch.add(a, b)\n",
        "\n",
        "# subtraction\n",
        "print(b-a, \"\\n\")       # equivalent to: torch.sub(b, a)\n",
        "\n",
        "# elementwise multiplication\n",
        "print(a*b, \"\\n\")       # equivalent to: torch.mul(a, b)\n",
        "\n",
        "# dot product\n",
        "print(a@torch.t(b), \"\\n\")       # equivalent to: torch.dot(a, b)\n",
        "\n",
        "# division\n",
        "print(b/a, \"\\n\")       # equivalent to: torch.div(b, a)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1.1793,  0.0495, -1.4038],\n",
            "        [ 0.2644, -0.7162,  0.5837]]) \n",
            "\n",
            "tensor([[ 0.5551,  0.4588,  0.6239],\n",
            "        [-0.3125, -1.2750, -1.5221]]) \n",
            "\n",
            "tensor([[ 0.2706, -0.0520,  0.3954],\n",
            "        [-0.0069, -0.2782, -0.4940]]) \n",
            "\n",
            "tensor([[ 0.6140,  0.6719],\n",
            "        [-0.0895, -0.7791]]) \n",
            "\n",
            "tensor([[ 2.7787, -1.2419,  0.3846],\n",
            "        [-0.0834, -3.5633, -0.4456]]) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZugTYV7xGC_",
        "colab_type": "text"
      },
      "source": [
        "2. Torch methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqzSCIVrj4T7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "5b9a2dde-1c90-4345-8d57-06619ff2501e"
      },
      "source": [
        "# addition\n",
        "print(torch.add(a, b), \"\\n\")\n",
        "\n",
        "# subtraction\n",
        "print(torch.sub(b, a), \"\\n\")\n",
        "\n",
        "# elementwise multiplication\n",
        "print(torch.mul(a, b), \"\\n\")\n",
        "\n",
        "# dot product\n",
        "print(torch.mm(a, torch.t(b)), \"\\n\")\n",
        "\n",
        "# division\n",
        "print(torch.div(b, a), \"\\n\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1.1793,  0.0495, -1.4038],\n",
            "        [ 0.2644, -0.7162,  0.5837]]) \n",
            "\n",
            "tensor([[ 0.5551,  0.4588,  0.6239],\n",
            "        [-0.3125, -1.2750, -1.5221]]) \n",
            "\n",
            "tensor([[ 0.2706, -0.0520,  0.3954],\n",
            "        [-0.0069, -0.2782, -0.4940]]) \n",
            "\n",
            "tensor([[ 0.6140,  0.6719],\n",
            "        [-0.0895, -0.7791]]) \n",
            "\n",
            "tensor([[ 2.7787, -1.2419,  0.3846],\n",
            "        [-0.0834, -3.5633, -0.4456]]) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shsKUNJ7yeAD",
        "colab_type": "text"
      },
      "source": [
        "3. Torch inplace methods\n",
        "\n",
        "  The inplace methods functionality is the same as the regular methods shown above, accept that their reult is written to the object they were operated on.\n",
        "The inplace methods always followed by an underscore."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cbKzQeXj4Sc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "23496c9b-73f8-4e93-afd6-7d9301a67d16"
      },
      "source": [
        "# addition\n",
        "a.add_(b)\n",
        "print(a, \"\\n\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.6801,  0.2148, -0.4094],\n",
            "        [-0.3647, -0.0793, -1.6675]]) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0SU3KKV0gCn",
        "colab_type": "text"
      },
      "source": [
        "### Concatenating"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCbZnCFANYZu",
        "colab_type": "text"
      },
      "source": [
        "Let’s say we have two tensors as shown below and we want to concatenate them\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZJ3PbNfM2ts",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "77cce4cd-de96-4b1b-cb6c-ba62a011110d"
      },
      "source": [
        "a = torch.tensor([[1,2],[3,4]])\n",
        "b = torch.tensor([[5,6],[7,8]])\n",
        "\n",
        "print(a, \"\\n\")\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4]]) \n",
            "\n",
            "tensor([[5, 6],\n",
            "        [7, 8]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrG7ypNSONrb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "9d5e8112-c291-4df1-829b-565bd2cda634"
      },
      "source": [
        "# concatenating vertically\n",
        "torch.cat((a,b))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4],\n",
              "        [5, 6],\n",
              "        [7, 8]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AO2QeXW8OMzo",
        "colab_type": "text"
      },
      "source": [
        "As you can see, the second tensor has been stacked below the first tensor. We can concatenate the tensors horizontally as well by setting the dim parameter to 1:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrcdmLMNONvX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "cace553c-df40-4fa0-f3e5-739cebd0927c"
      },
      "source": [
        "# concatenating horizontally\n",
        "torch.cat((a,b),dim=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 5, 6],\n",
              "        [3, 4, 7, 8]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ylevJwi7IQS",
        "colab_type": "text"
      },
      "source": [
        "### Accumulating Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DTk3ITq7NCr",
        "colab_type": "text"
      },
      "source": [
        "The accumulating functions are mostly the same in torch tensors as in numpy arrays.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrpBYCA77NKo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e4fbed66-69a6-4de2-e4cb-e7bf3abd5584"
      },
      "source": [
        "a = torch.tensor([[1,2],[3,4]], dtype=torch.float32)\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYIN_LJv7NNM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8b329c14-a4dc-4d8d-f748-7ff386671670"
      },
      "source": [
        "a_sum = a.sum()\n",
        "print(f\"a.sum() = {a_sum}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a.sum() = 10.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtQqPjXm8BjJ",
        "colab_type": "text"
      },
      "source": [
        "Similarily to numpy, you can specify the axis which you want to accumulate along: \n",
        "\n",
        "``axis=0`` for columns and ``axis=1`` for rows (as oppose to numpy)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOy3HRB28A4m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c7d7535a-9b9e-4c68-d073-ce7170521302"
      },
      "source": [
        "# the mean of each column in the tensor a:\n",
        "a.mean(axis=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2., 3.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_NRl1wa8oOm",
        "colab_type": "text"
      },
      "source": [
        "A very important function to use after you have done an accumulationg operation is the ``torch.item`` function.\n",
        "This function return a scalar from a tensor which contain only one item in it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCdHLI5E8oiR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "2a68f94f-3a3f-4e0a-ded4-4035c858d6f0"
      },
      "source": [
        "x = torch.tensor([[1]])\n",
        "print(x, \"\\n\")\n",
        "\n",
        "print(x.item())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1]]) \n",
            "\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSZU5uiVJdHK",
        "colab_type": "text"
      },
      "source": [
        "Unlike numpy, `torch.max` return both the maximal element in  a tensor and its index.\n",
        "\n",
        "Use `dim=1` to maximize over each row of the tensor columns and `dims=0` to maximize over each column of the tensor rows.\n",
        "\n",
        "Take a moment and think, why is it useful? Yoy will see in the upcoming chapters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzTGGCYbJdUE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "63aac89b-cc9d-4c25-b9b2-1488ebf77c65"
      },
      "source": [
        "x = torch.randn(3,5)\n",
        "print(x, \"\\n\")\n",
        "\n",
        "value, index = torch.max(x, dim=1) \n",
        "print(value)\n",
        "print(index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1.5276,  0.6673, -0.3035, -0.7540,  0.4225],\n",
            "        [ 0.2723, -0.2668,  0.8657,  1.4652,  0.4425],\n",
            "        [ 0.6219,  0.8103, -0.7368, -1.6926, -0.7497]]) \n",
            "\n",
            "tensor([1.5276, 1.4652, 0.8103])\n",
            "tensor([0, 3, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7-lvSU04P84",
        "colab_type": "text"
      },
      "source": [
        "### Numpy Bridge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dd1yfLYlaL2S",
        "colab_type": "text"
      },
      "source": [
        "Converting a torch Tensor to a numpy array and vice versa is a breeze. The torch Tensor and numpy array will share their underlying memory locations, and changing one will change the other."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0FzZ-bRVixy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "c877874c-7b5c-4468-fa5a-86c61b6e6dbf"
      },
      "source": [
        "a = np.array([[1,2],[3,4]])\n",
        "print(a, \"\\n\")\n",
        "\n",
        "tensor = torch.from_numpy(a)\n",
        "print(tensor)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 2]\n",
            " [3 4]] \n",
            "\n",
            "tensor([[1, 2],\n",
            "        [3, 4]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kql-nhgs5f16",
        "colab_type": "text"
      },
      "source": [
        "Pay attenation that the numpy array and the torch tensor share the same memory,\n",
        "if you change the numpy array you chang the tensor and vice versa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siljsQ_15uF2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "6db949c8-1daa-44db-c7df-066bc4e043e8"
      },
      "source": [
        "a[0,0] = 5\n",
        "print(tensor, \"\\n\")\n",
        "\n",
        "tensor[0,0] = 6\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[5, 2],\n",
            "        [3, 4]]) \n",
            "\n",
            "[[6 2]\n",
            " [3 4]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2GkB-AoafXX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2fbc9ebc-4816-481b-d2ba-b916efbb291c"
      },
      "source": [
        "b = tensor.numpy()\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6 2]\n",
            " [3 4]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0yYyIDi-DVy",
        "colab_type": "text"
      },
      "source": [
        "## Autograd: Automatic Differentiation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xkgH6MiOs5g",
        "colab_type": "text"
      },
      "source": [
        "Central to all neural networks in PyTorch is the ``autograd`` package. Let’s first briefly visit this.\n",
        "\n",
        "The autograd package provides automatic differentiation for all operations on Tensors. \n",
        "\n",
        "It is a define-by-run framework, which means that your backprop is defined by how your code is run, and that every single iteration can be different."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Dd2RLo3QRp2",
        "colab_type": "text"
      },
      "source": [
        "``torch.Tensor``, which you saw above, is the central class of the package. \n",
        "\n",
        "If you set its attribute ``.requires_grad`` as ``True``, it starts to track all operations on it. \n",
        "\n",
        "When you finish your computation you can call ``.backward()`` and have all the gradients computed automatically. \n",
        "\n",
        "The gradient for this tensor will be accumulated into .grad attribute."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9RTTP0CTDFc",
        "colab_type": "text"
      },
      "source": [
        "There’s one more class which is very important for the autograd implementation - a ``Function``.\n",
        "\n",
        "Tensor and Function are interconnected and build up an acyclic graph, that encodes a complete history of computation. Each tensor has a ``.grad_fn`` attribute that references to a Function that has created the Tensor (except for Tensors created by the user - their ``grad_fn`` is ``None``).\n",
        "\n",
        "If you want to compute the derivatives, you can call ``.backward()`` on a Tensor. If Tensor is a scalar (i.e. it holds a one element data), you don’t need to specify any arguments to ``backward()``, however if it has more elements, you need to specify a gradient argument that is a tensor of matching shape."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNQhjE4y4xyd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f0b30a75-3ece-466f-ae90-2fd3ae51783c"
      },
      "source": [
        "x = torch.ones(2, 2, requires_grad=True)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIA4YePZ4x2S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "f53dbf89-b515-49ef-9da1-c20318df0164"
      },
      "source": [
        "y = x + 2\n",
        "print(y, \"\\n\")\n",
        "\n",
        "z = y * y * 3\n",
        "print(z, \"\\n\")\n",
        "\n",
        "out = z.mean()\n",
        "print(out)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[3., 3.],\n",
            "        [3., 3.]], grad_fn=<AddBackward0>) \n",
            "\n",
            "tensor([[27., 27.],\n",
            "        [27., 27.]], grad_fn=<MulBackward0>) \n",
            "\n",
            "tensor(27., grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_E-J1QQeUzRW",
        "colab_type": "text"
      },
      "source": [
        "Let’s backprop now. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r85e9PXCSIiH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fv7Iks0oVIcp",
        "colab_type": "text"
      },
      "source": [
        "Print gradients d(out)/dx"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HKyiBpdSIlN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a6e9a057-59df-4242-a7b1-75244fffb22a"
      },
      "source": [
        "print(x.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[4.5000, 4.5000],\n",
            "        [4.5000, 4.5000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR5AThjyWzrC",
        "colab_type": "text"
      },
      "source": [
        "Calculating the gradients with respect to all of our parameters is time-consuming.\n",
        "\n",
        "Therefore, there are times when we don't want the gradients to be computed.\n",
        "\n",
        "There are 3 ways to stop the gradients calculations:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oqjap_IXSNE",
        "colab_type": "text"
      },
      "source": [
        "1. Updating the ``.requires_grad`` attribute as ``False``"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYciquXkSIgr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "cf0ff6df-daaa-4fed-ccf6-cf2fc44aba94"
      },
      "source": [
        "a = torch.randn(3, requires_grad=True)\n",
        "print(a)\n",
        "print(a.requires_grad, \"\\n\")\n",
        "\n",
        "a.requires_grad_(False)\n",
        "\n",
        "print(a)\n",
        "print(a.requires_grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-0.5733, -0.6450, -0.0432], requires_grad=True)\n",
            "True \n",
            "\n",
            "tensor([-0.5733, -0.6450, -0.0432])\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DB6nqFYKX8f9",
        "colab_type": "text"
      },
      "source": [
        "2. Call .detach()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19A5z1J9SIaN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "fb497e11-8d2a-428c-c464-b6ae6ed3ef3b"
      },
      "source": [
        "a = torch.randn(3, requires_grad=True)\n",
        "print(a)\n",
        "print(a.requires_grad, \"\\n\")\n",
        "\n",
        "b = a.detach()\n",
        "\n",
        "print(b)\n",
        "print(b.requires_grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-0.0601,  0.5046, -1.4813], requires_grad=True)\n",
            "True \n",
            "\n",
            "tensor([-0.0601,  0.5046, -1.4813])\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBVUsH9UY9ZR",
        "colab_type": "text"
      },
      "source": [
        "Pay attention that the gradients above share the same memory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqqRo3Y0ZFXT",
        "colab_type": "text"
      },
      "source": [
        "3. Using the ``with`` statement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH77Bg30ZFoi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "4f0007db-7495-48c4-82ff-39117aa4809c"
      },
      "source": [
        "a = torch.randn(3, requires_grad=True)\n",
        "print(a)\n",
        "print(a.requires_grad, \"\\n\")\n",
        "\n",
        "with torch.no_grad():\n",
        "  b = a+2\n",
        "  print(b)\n",
        "  print(b.requires_grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-0.3377, -0.6099,  0.1613], requires_grad=True)\n",
            "True \n",
            "\n",
            "tensor([1.6623, 1.3901, 2.1613])\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Fj56RHmaQZ-",
        "colab_type": "text"
      },
      "source": [
        "As mentioned earlier, the gradients are accumulated in the ``.grad``  attribute.\n",
        "\n",
        "Let's see an example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PT-pzsbarhF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "4aab472f-6cde-4afa-fea2-692562e82c36"
      },
      "source": [
        "weights = torch.ones(4, requires_grad=True)\n",
        "\n",
        "for epoch in range(3):\n",
        "    model_output = (weights*3).sum()\n",
        "    model_output.backward()\n",
        "    \n",
        "    print(weights.grad)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([3., 3., 3., 3.])\n",
            "tensor([6., 6., 6., 6.])\n",
            "tensor([9., 9., 9., 9.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzJBdvUKkcpU",
        "colab_type": "text"
      },
      "source": [
        "That isn't what we want.\n",
        "\n",
        "We must zero the gradients before each iteration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pN1DfRa8arkH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "cfbc4531-4fcd-4cb8-80a2-981cb580b3c9"
      },
      "source": [
        "weights = torch.ones(4, requires_grad=True)\n",
        "\n",
        "for epoch in range(3):\n",
        "    model_output = (weights*3).sum()\n",
        "    model_output.backward()\n",
        "  \n",
        "    print(weights.grad)\n",
        "\n",
        "    weights.grad.zero_()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maZnGuwo-bEu",
        "colab_type": "text"
      },
      "source": [
        "##  Training Pipeline Overview: Model, Loss, and Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqWvVHn4B2Tm",
        "colab_type": "text"
      },
      "source": [
        "There are 3 common steps in order to make NN using pytorch.\n",
        "1. Design model (input, output, forward pass with different layers).\n",
        "2. Construct loss and optimizer.\n",
        "3. Training loop:\n",
        "      - Forward - compute prediction and loss.\n",
        "      - Backward - compute gradients.\n",
        "      - Update weights.\n",
        "\n",
        "Its important to understand the different components of the process and the well defined separation between them.\n",
        "- Forward - only needs the X features, and the current weights.\n",
        "- Backward - only needs the y label and the y_predicted to be given to the loss. So the gradients can be acumulated with respect to the loss (being calculated using ``loss.backprop()``).\n",
        "- Update weights - only needs the gradients and the optimizing method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOMMiUS8-iTA",
        "colab_type": "text"
      },
      "source": [
        "##  Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PheQ9BoSoYvU",
        "colab_type": "text"
      },
      "source": [
        "Here is our first very simple example of NN.\n",
        "\n",
        "This NN implements the simple linear regression.\n",
        "\n",
        "The most important thing to take from this example is the structure of our code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCRTjGO5pO_r",
        "colab_type": "text"
      },
      "source": [
        "First, let's make a small dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPSRp6zG_vk4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_numpy, y_numpy = datasets.make_regression(n_samples=100, \n",
        "                                            n_features=1, \n",
        "                                            noise=15, \n",
        "                                            random_state=42)\n",
        "\n",
        "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
        "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
        "y = y.view(y.shape[0], 1)\n",
        "\n",
        "n_samples, n_features = X.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCuQh5twsVqr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "3a255c4e-d53b-4171-abad-abb6b43ce37f"
      },
      "source": [
        "plt.scatter(X , y)\n",
        "plt.title(\"Linear Regression Data\")\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"y\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'y')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avnbhCM8DQLH",
        "colab_type": "text"
      },
      "source": [
        "Step No. 1:\n",
        "\n",
        "We define our NN as a class that inherite from ``nn.Module``.\n",
        "\n",
        "In this class we must implement two methods: the ``__init__`` method\n",
        "and the ``forward`` method.\n",
        "\n",
        "In the ``__init__`` method we firstly calling ``nn.Module`` ``__init__`` and then we define our NN layers, their input and outputs sizes.\n",
        "\n",
        "The  ``forward`` method performs the forward propagtion using the layers defined in the initialization. Most layers are already implemented for you in the ``nn`` module of pytorch. the first layer to be used is a ``nn.Linear`` layer, defined by its input dimenstions and output dimensions, storing the wights inside. In order to apply the layer one need just to pass an X to it as if it was a function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6x9Vt_nnsuE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LinearRegression(nn.Module):\n",
        "\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    super(LinearRegression, self).__init__()\n",
        "\n",
        "    self.lin = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.lin(x)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-xkf4Ywns2U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "de6ad2d9-7a9e-44d2-ea00-7e0dcf1b7f52"
      },
      "source": [
        "model = LinearRegression(n_features, 1)\n",
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(\n",
              "  (lin): Linear(in_features=1, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dZUiVhaav1k",
        "colab_type": "text"
      },
      "source": [
        "Model class was made so it will contain layers that operate in a sequence. As such, a very convineint way to reffer to all parameters of all layers is the method ``.parameters()``."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHubETGnsyBt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w, b = model.parameters()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHwacilQtrG7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "2a63528f-0775-4e44-f43f-b041559e4719"
      },
      "source": [
        "plt.plot(X, w.item()*X+b.item(), c=\"r\")\n",
        "plt.scatter(X, y)\n",
        "plt.title(\"Initial Model\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'y')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oe3E08-SGMAw",
        "colab_type": "text"
      },
      "source": [
        "Step No 2.\n",
        "\n",
        "We define our loss function from ``torch.nn`` and our optimizer from ``torch.optim``. \n",
        "\n",
        "Notice that as ``nn.Linear``, a loss function is just another layer function operating on a layer output - simply with no weights stored inside. which puts it in the ``torch.nn`` module.\n",
        "\n",
        "Also notice how an optimizer needs to accept the parameters on which to optimize on. In the example above we chose to include all parameters off the model in the optimizing process. In other scenarios, For example in transfer learning, we would want to limit the parameters to be optimizing on just the last layers and not change the first layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xuF6BgSns1M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLcVQdXEGom7",
        "colab_type": "text"
      },
      "source": [
        "Step No 3.\n",
        "\n",
        "Here we perform our training loop.\n",
        "\n",
        "- forward propagation.\n",
        "- computing loss.\n",
        "- back propagation.\n",
        "- parameters update."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WbHgpHMrFHP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "6f33969c-5770-4e0e-c4a0-4eff4823629d"
      },
      "source": [
        "for epoch in range(n_iters):\n",
        "    # predict = forward pass with our model\n",
        "    y_predicted = model(X)\n",
        "\n",
        "    # loss\n",
        "    l = loss(y_predicted, y)\n",
        "\n",
        "    # calculate gradients = backward pass\n",
        "    l.backward()\n",
        "\n",
        "    # update weights\n",
        "    optimizer.step()\n",
        "\n",
        "    # zero the gradients after updating\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        w, b = model.parameters()\n",
        "        print('epoch ', epoch+1,' loss = ', l.item())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch  10  loss =  177.0533447265625\n",
            "epoch  20  loss =  176.6653289794922\n",
            "epoch  30  loss =  176.38275146484375\n",
            "epoch  40  loss =  176.1767578125\n",
            "epoch  50  loss =  176.0266571044922\n",
            "epoch  60  loss =  175.91722106933594\n",
            "epoch  70  loss =  175.83741760253906\n",
            "epoch  80  loss =  175.7792205810547\n",
            "epoch  90  loss =  175.73675537109375\n",
            "epoch  100  loss =  175.7057647705078\n",
            "epoch  110  loss =  175.6831817626953\n",
            "epoch  120  loss =  175.6667022705078\n",
            "epoch  130  loss =  175.65460205078125\n",
            "epoch  140  loss =  175.64584350585938\n",
            "epoch  150  loss =  175.63938903808594\n",
            "epoch  160  loss =  175.63475036621094\n",
            "epoch  170  loss =  175.63128662109375\n",
            "epoch  180  loss =  175.62881469726562\n",
            "epoch  190  loss =  175.62696838378906\n",
            "epoch  200  loss =  175.6256866455078\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-HKQCRHrFKr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w, b = model.parameters()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KJSWDh2rFNi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "4e52f352-3354-48cf-f18a-0f36db9bf732"
      },
      "source": [
        "plt.plot(X, w.item()*X+b.item(), c=\"r\")\n",
        "plt.scatter(X, y)\n",
        "plt.title(\"Final Model\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'y')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-84Y2lymdYm0",
        "colab_type": "text"
      },
      "source": [
        "Try running the training again and examine what happened. Do you expect that to happen?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c592nR1__vsZ",
        "colab_type": "text"
      },
      "source": [
        "## ✍️  Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vp61bcpnPGUj",
        "colab_type": "text"
      },
      "source": [
        "In this section, you ware going to implement logistic regression using pytorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLqmXnU4N2j4",
        "colab_type": "text"
      },
      "source": [
        "A short reminder of logistic regression:\n",
        "\n",
        "Let  $W$ be our parametrs matrix and $b$ our bias.\n",
        "\n",
        "The logistic function is defined by the following formula of the sigmoid function:\n",
        "\n",
        "$\\sigma(x; W,b) = \\frac{1}{1+e^{-(W\\cdot x+b)}}$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnCugy93ekzB",
        "colab_type": "text"
      },
      "source": [
        "✍️ Step No. 0:\n",
        "\n",
        "Load the data and shape it so you can train a model on it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjCCelGB_104",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bc = datasets.load_breast_cancer()\n",
        "X, y = bc.data, bc.target\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "### ✍️ Split your data to train set and test set. Use 20% of your data as test.\n",
        "### START CODE HERE ### (1 line of code)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "### END CODE HERE ###\n",
        "\n",
        "\n",
        "### ✍️ Scale your data using the StandardScaler.\n",
        "### START CODE HERE ### (~3 lines of code)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "### END CODE HERE ###\n",
        "\n",
        "### ✍️ Transform your data and labels to tensors. \n",
        "### Don't forget to convert their dtype to float32.\n",
        "### START CODE HERE ### (4 lines of code)\n",
        "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
        "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
        "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
        "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
        "### END CODE HERE ###\n",
        "\n",
        "### ✍️ Reshape your lables.\n",
        "### START CODE HERE ### (2 lines of code)\n",
        "y_train = y_train.view(y_train.shape[0], 1)\n",
        "y_test = y_test.view(y_test.shape[0], 1)\n",
        "### END CODE HERE ###\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBe0LDX_k-7V",
        "colab_type": "text"
      },
      "source": [
        "✍️ Step No. 1:\n",
        "\n",
        "Define the LogisticRegression model. (read relevant layers in the nn documentaion)\n",
        "\n",
        "In the ``__init__`` method, define the layer and the activation.\n",
        "\n",
        "In the ``forward`` method, define forward propagartion.\n",
        "\n",
        "Finally, initiate a new LogisticRegression instance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBOujCq4kzWQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "11acf877-781d-4643-f890-04701c856d14"
      },
      "source": [
        "class LogisticRegression(nn.Module):\n",
        "    def __init__(self, n_input_features):\n",
        "        super(LogisticRegression, self).__init__()\n",
        "        ### START CODE HERE ### (2 lines of code)\n",
        "        self.linear = nn.Linear(n_input_features, 1)\n",
        "        self.sig = nn.Sigmoid()\n",
        "        ### END CODE HERE ###\n",
        "\n",
        "    def forward(self, x):\n",
        "        ### START CODE HERE ### (~1-3 lines of code)\n",
        "        out = self.linear(x)\n",
        "        out = self.sig(out)\n",
        "        return out\n",
        "        ### END CODE HERE ###\n",
        "\n",
        "### START CODE HERE ### (1 line of code)\n",
        "model = LogisticRegression(n_features)\n",
        "### END CODE HERE ###\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression(\n",
            "  (linear): Linear(in_features=30, out_features=1, bias=True)\n",
            "  (sig): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTApwLFLsRHC",
        "colab_type": "text"
      },
      "source": [
        "✍️ Step No 2.\n",
        "\n",
        "Now, we define our loss function as the binary cross-entropy loss,\n",
        "\n",
        "and stochastic gradient-descent as our optimization algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctCEZoq_mmgz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_epochs = 100\n",
        "learning_rate = 0.01\n",
        "\n",
        "### START CODE HERE ### (2 lines of code)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "### END CODE HERE ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYlGomS5tt7a",
        "colab_type": "text"
      },
      "source": [
        "✍️ Step No 3.\n",
        "\n",
        "Now, we perform our training loop.\n",
        "\n",
        "- forward propagation.\n",
        "- computing loss.\n",
        "- back propagation.\n",
        "- parameters update."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFz9m1-yYN1z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "9941d9cf-27ed-40a0-ddb3-1704ed93e2e0"
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "\n",
        "  ### Forward pass\n",
        "  ### START CODE HERE ### (1 line of code)\n",
        "  y_pred = model(X_train)\n",
        "  ### END CODE HERE ###\n",
        "\n",
        "  ### Loss calculation\n",
        "  ### START CODE HERE ### (1 line of code)\n",
        "  loss = criterion(y_pred, y_train)\n",
        "  ### END CODE HERE ###\n",
        "\n",
        "  ### Backward pass\n",
        "  ### START CODE HERE ### (3 lines of code)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "  ### END CODE HERE ###\n",
        "\n",
        "  ### Print loss every 10 epochs\n",
        "  ### START CODE HERE ### (2 lines of code)\n",
        "  if (epoch+1) % 10 == 0:\n",
        "    print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
        "  ### END CODE HERE ###"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 10, loss = 0.7302\n",
            "epoch: 20, loss = 0.5709\n",
            "epoch: 30, loss = 0.4795\n",
            "epoch: 40, loss = 0.4210\n",
            "epoch: 50, loss = 0.3799\n",
            "epoch: 60, loss = 0.3493\n",
            "epoch: 70, loss = 0.3253\n",
            "epoch: 80, loss = 0.3059\n",
            "epoch: 90, loss = 0.2898\n",
            "epoch: 100, loss = 0.2762\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svP4MtRy0RAp",
        "colab_type": "text"
      },
      "source": [
        "✍️ Finally, We must check how our model perforn on the test set.\n",
        "\n",
        "In this part we make a forward pass, however, we don't want the gradient to be calculated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGGrV4aSYOP6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5b010a81-bc37-43ea-dc1b-6a74187ea2f5"
      },
      "source": [
        "### Compute the test accuracy. \n",
        "### Use 0.5 as the classification border, samples with sigmoid result greater\n",
        "### or equal to 0.5 will be classified as class 1, \n",
        "### and all the others will be classifies as class 0.\n",
        "### START CODE HERE ### (~5 lines of code)\n",
        "with torch.no_grad():\n",
        "    y_predicted = model(X_test)\n",
        "    y_predicted_cls = y_predicted.round()\n",
        "    acc = y_predicted_cls.eq(y_test).sum() / float(y_test.shape[0])\n",
        "    print(f'accuracy: {acc.item():.4f}')\n",
        "### END CODE HERE ###"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.9737\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lWfOt4J_3Va",
        "colab_type": "text"
      },
      "source": [
        "## Dataset and DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3RQHq5SHDyN",
        "colab_type": "text"
      },
      "source": [
        "As You probably saw in Andrew's course,\n",
        "the gradient computation is not efficient for the whole data set.\n",
        "\n",
        "Therefore, we divide the dataset into small batches, and compute the gradient on each batch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3xcskOxHnP3",
        "colab_type": "text"
      },
      "source": [
        "A short reminder about the defenitions regarding this part:\n",
        "- epoch - one forward and backward pass of ALL training samples.\n",
        "- batch_size - number of training samples used in one forward/backward pass.\n",
        "- number of iterations - number of passes, each pass (forward+backward) using #batch_size number of sampes.\n",
        "\n",
        "e.g : 100 samples, batch_size=20 -> 100/20=5 iterations for 1 epoch.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRjFq-LvTREl",
        "colab_type": "text"
      },
      "source": [
        "As explained above it might be a good idea to an object representing a Dataset to so we can feed the model in training time.\n",
        "\n",
        "In order to implement such a Dataset, we will inherit the class ``Dataset`` of pytorch.\n",
        "\n",
        "We will implement the following methods: ``__init__``, ``__getitem__`` , and ``__len__``,\n",
        "\n",
        "using the scikit-learn wine dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUn0SOxd_66l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class WineDataset(Dataset):\n",
        "\n",
        "    def __init__(self):\n",
        "        data = datasets.load_wine(return_X_y=True)\n",
        "        self.n_samples = len(data[1])\n",
        "\n",
        "        self.x_data = torch.from_numpy(data[0])\n",
        "        self.y_data = torch.from_numpy(data[1]) \n",
        "\n",
        "    # support indexing such that dataset[i] can be used to get i-th sample\n",
        "    def __getitem__(self, index):\n",
        "        return self.x_data[index], self.y_data[index]\n",
        "\n",
        "    # we can call len(dataset) to return the size\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "\n",
        "\n",
        "# create dataset\n",
        "dataset = WineDataset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfSBV-rXVYhD",
        "colab_type": "text"
      },
      "source": [
        "Now, let's see that we can get the first sample:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ux3zQCxtVSg9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c3cf42ec-cb49-4bce-b2cd-606770d724d2"
      },
      "source": [
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(features, \"\\n\", labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
            "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
            "        1.0650e+03], dtype=torch.float64) \n",
            " tensor(0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sx4xARqVVCsH",
        "colab_type": "text"
      },
      "source": [
        "Once we defined our ``Dataset`` object we can use the already implemented ``DataLoader`` class wraping the ``Dataset`` object with batching skills and more.\n",
        "\n",
        "The main aim of the ``DataLoader`` is to provide us a convinient way to iterate through the batches of our dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSsyXPuZVC4u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_loader = DataLoader(dataset=dataset,\n",
        "                          batch_size=5,\n",
        "                          shuffle=True,\n",
        "                          num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALJMBrR-bNRB",
        "colab_type": "text"
      },
      "source": [
        "We have just defined our data loader,\n",
        "\n",
        "now, let's convert it to an iterator and look at one random sample."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EyzOR5KVC7l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "0326b29b-037c-41bc-f04d-ccf5fa9a0f08"
      },
      "source": [
        "dataiter = iter(data_loader)\n",
        "data = dataiter.next()\n",
        "features, labels = data\n",
        "print(features, \"\\n\", labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1.4390e+01, 1.8700e+00, 2.4500e+00, 1.4600e+01, 9.6000e+01, 2.5000e+00,\n",
            "         2.5200e+00, 3.0000e-01, 1.9800e+00, 5.2500e+00, 1.0200e+00, 3.5800e+00,\n",
            "         1.2900e+03],\n",
            "        [1.3780e+01, 2.7600e+00, 2.3000e+00, 2.2000e+01, 9.0000e+01, 1.3500e+00,\n",
            "         6.8000e-01, 4.1000e-01, 1.0300e+00, 9.5800e+00, 7.0000e-01, 1.6800e+00,\n",
            "         6.1500e+02],\n",
            "        [1.1450e+01, 2.4000e+00, 2.4200e+00, 2.0000e+01, 9.6000e+01, 2.9000e+00,\n",
            "         2.7900e+00, 3.2000e-01, 1.8300e+00, 3.2500e+00, 8.0000e-01, 3.3900e+00,\n",
            "         6.2500e+02],\n",
            "        [1.3390e+01, 1.7700e+00, 2.6200e+00, 1.6100e+01, 9.3000e+01, 2.8500e+00,\n",
            "         2.9400e+00, 3.4000e-01, 1.4500e+00, 4.8000e+00, 9.2000e-01, 3.2200e+00,\n",
            "         1.1950e+03],\n",
            "        [1.1660e+01, 1.8800e+00, 1.9200e+00, 1.6000e+01, 9.7000e+01, 1.6100e+00,\n",
            "         1.5700e+00, 3.4000e-01, 1.1500e+00, 3.8000e+00, 1.2300e+00, 2.1400e+00,\n",
            "         4.2800e+02]], dtype=torch.float64) \n",
            " tensor([0, 2, 1, 0, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SA1zs4OyXikV",
        "colab_type": "text"
      },
      "source": [
        "✍️ Iterate through the batches of the dataset.\n",
        "For each batch print how much samples it has from each class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvjJQWFwXMQj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "eb7de328-4cf9-4ec1-db81-2cf9eca620ca"
      },
      "source": [
        "### START CODE HERE ### (~5 lines of code)\n",
        "for i, (inputs, labels) in enumerate(data_loader):\n",
        "  class_0 = sum(labels == 0).item()\n",
        "  class_1 = sum(labels == 1).item()\n",
        "  class_2 = sum(labels == 2).item()\n",
        "\n",
        "  print(f'In batch {i+1}: class 0 : {class_0},  class 1: {class_1},  class 2 : {class_2}')\n",
        "### END CODE HERE ###"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "In batch 1: class 0 : 3,  class 1: 1,  class 2 : 1\n",
            "In batch 2: class 0 : 3,  class 1: 1,  class 2 : 1\n",
            "In batch 3: class 0 : 0,  class 1: 5,  class 2 : 0\n",
            "In batch 4: class 0 : 3,  class 1: 1,  class 2 : 1\n",
            "In batch 5: class 0 : 3,  class 1: 1,  class 2 : 1\n",
            "In batch 6: class 0 : 2,  class 1: 0,  class 2 : 3\n",
            "In batch 7: class 0 : 1,  class 1: 2,  class 2 : 2\n",
            "In batch 8: class 0 : 1,  class 1: 3,  class 2 : 1\n",
            "In batch 9: class 0 : 1,  class 1: 3,  class 2 : 1\n",
            "In batch 10: class 0 : 1,  class 1: 4,  class 2 : 0\n",
            "In batch 11: class 0 : 1,  class 1: 2,  class 2 : 2\n",
            "In batch 12: class 0 : 1,  class 1: 2,  class 2 : 2\n",
            "In batch 13: class 0 : 1,  class 1: 0,  class 2 : 4\n",
            "In batch 14: class 0 : 3,  class 1: 1,  class 2 : 1\n",
            "In batch 15: class 0 : 1,  class 1: 2,  class 2 : 2\n",
            "In batch 16: class 0 : 0,  class 1: 3,  class 2 : 2\n",
            "In batch 17: class 0 : 0,  class 1: 3,  class 2 : 2\n",
            "In batch 18: class 0 : 3,  class 1: 1,  class 2 : 1\n",
            "In batch 19: class 0 : 2,  class 1: 3,  class 2 : 0\n",
            "In batch 20: class 0 : 1,  class 1: 2,  class 2 : 2\n",
            "In batch 21: class 0 : 1,  class 1: 3,  class 2 : 1\n",
            "In batch 22: class 0 : 2,  class 1: 2,  class 2 : 1\n",
            "In batch 23: class 0 : 2,  class 1: 3,  class 2 : 0\n",
            "In batch 24: class 0 : 3,  class 1: 2,  class 2 : 0\n",
            "In batch 25: class 0 : 1,  class 1: 3,  class 2 : 1\n",
            "In batch 26: class 0 : 1,  class 1: 2,  class 2 : 2\n",
            "In batch 27: class 0 : 2,  class 1: 1,  class 2 : 2\n",
            "In batch 28: class 0 : 2,  class 1: 0,  class 2 : 3\n",
            "In batch 29: class 0 : 3,  class 1: 2,  class 2 : 0\n",
            "In batch 30: class 0 : 2,  class 1: 3,  class 2 : 0\n",
            "In batch 31: class 0 : 2,  class 1: 2,  class 2 : 1\n",
            "In batch 32: class 0 : 2,  class 1: 2,  class 2 : 1\n",
            "In batch 33: class 0 : 1,  class 1: 1,  class 2 : 3\n",
            "In batch 34: class 0 : 2,  class 1: 2,  class 2 : 1\n",
            "In batch 35: class 0 : 2,  class 1: 2,  class 2 : 1\n",
            "In batch 36: class 0 : 0,  class 1: 1,  class 2 : 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMPdPmMDZMZH",
        "colab_type": "text"
      },
      "source": [
        "This exercise purpose is to let you find on your own the best and most convinient way to write the ``for`` loop command that iterate througt the batches."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWwEpMST_7c6",
        "colab_type": "text"
      },
      "source": [
        "## Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGJQsNAiE2u4",
        "colab_type": "text"
      },
      "source": [
        "Transforms can be applied to PIL images, tensors, ndarrays, or custom data\n",
        "during creation of the DataSet.\n",
        "\n",
        "You can find the complete list of built-in transforms here: \n",
        "https://pytorch.org/docs/stable/torchvision/transforms.html\n",
        "\n",
        "Usually, transformers are sent while initializing the dataset as an optional paramrter.\n",
        "Then the transform, if it exists, is being operated in the ``__getitem__`` method. \n",
        "\n",
        "In this way one can use transformers to delay some pre-process to realtime or make the pre-process depend on the batch itself. \n",
        "But mainly this is used to do augmentaions that varies with every iteration, and has an intrinsic randomness. We will see some examples in this chapter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgBtHp2cE-aq",
        "colab_type": "text"
      },
      "source": [
        "Some common transforms which you can find implemented in ``torchvision.transforms``:\n",
        "\n",
        "\n",
        "- On Images:\n",
        "\n",
        "> CenterCrop, Grayscale, Pad, RandomAffine, RandomCrop, RandomHorizontalFlip, RandomRotation, Resize, Scale.\n",
        "\n",
        "\n",
        "\n",
        "- On Tensors:\n",
        "\n",
        "> LinearTransformation, Normalize, RandomErasing.\n",
        "\n",
        "- Conversion:\n",
        "\n",
        "> ToPILImage: from tensor or ndrarray.\n",
        "\n",
        "> ToTensor : from numpy.ndarray or PILImage.\n",
        "\n",
        "- Custom:\n",
        "\n",
        "> Write your own class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpglC4AHbrvW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LinearData(Dataset):\n",
        "  \n",
        "  def __init__(self, n_samples=100, transform=None):\n",
        "    X,y = datasets.make_regression(n_samples=n_samples,\n",
        "                                   n_features=1,\n",
        "                                   noise=15,\n",
        "                                   random_state=42)   \n",
        "    self.x = X\n",
        "    self.y = y.reshape((n_samples, -1))\n",
        "    self.n_samples = n_samples\n",
        "    self.transform = transform\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    sample = self.x[index], self.y[index]\n",
        "    if self.transform:\n",
        "      sample = self.transform(sample)\n",
        "    return sample\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.n_samples\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDyIX-J6Nd1w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ToFloat32:\n",
        "    def __call__(self, sample):\n",
        "        inputs, targets = sample\n",
        "        return inputs.astype(\"float32\"), targets.astype(\"float32\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-Kg-fdpPV4_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "a69e3402-99b3-41a2-cf77-1bb241820b72"
      },
      "source": [
        "print('Without transform:')\n",
        "dataset = LinearData(n_samples=500)\n",
        "features, labels = dataset[0]\n",
        "print(features.dtype, labels.dtype, \"\\n\")\n",
        "\n",
        "print('With transform to float32:')\n",
        "dataset = LinearData(n_samples=500, transform=ToFloat32())\n",
        "features, labels = dataset[0]\n",
        "print(features.dtype, labels.dtype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Without transform:\n",
            "float64 float64 \n",
            "\n",
            "With transform to float32:\n",
            "float32 float32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zp1hiSkOz2s",
        "colab_type": "text"
      },
      "source": [
        "✍️ Implement ToTensor transform.\n",
        "\n",
        "  Show that your transform works."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BscvwvbMbw2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### START CODE HERE ### (~4 lines of code)\n",
        "class ToTensor:\n",
        "  def __call__(self, sample):\n",
        "    inputs, targets = sample\n",
        "    return torch.from_numpy(inputs), torch.from_numpy(targets)\n",
        "### END CODE HERE ###  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNBATEPxRsZe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "af23603b-2b75-4113-b38b-b4e835b2cacc"
      },
      "source": [
        "### START CODE HERE ### (~8 lines of code)\n",
        "print('Without transform:')\n",
        "dataset = LinearData(n_samples=500)\n",
        "features, labels = dataset[0]\n",
        "print(type(features), type(labels), \"\\n\")\n",
        "\n",
        "print('With tensor transform:')\n",
        "dataset = LinearData(n_samples=500, transform=ToTensor())\n",
        "features, labels = dataset[0]\n",
        "print(type(features), type(labels))\n",
        "### END CODE HERE ###  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Without transform:\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'> \n",
            "\n",
            "With tensor transform:\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UF7QvPTgUSBO",
        "colab_type": "text"
      },
      "source": [
        "✍️ Implement MulTransform. This transformer have to get a factor and multiply the labels with this given factor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZoy8D8jtL55",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### START CODE HERE ### (~7 lines of code)\n",
        "class MulTransform:\n",
        "    def __init__(self, factor):\n",
        "        self.factor = factor\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        input, target = sample\n",
        "        target *= self.factor\n",
        "        return input, target\n",
        "### END CODE HERE ###  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4cjLfrBudsO",
        "colab_type": "text"
      },
      "source": [
        "✍️ Now, after we have built 3 transformers, let's compose them.\n",
        "\n",
        "Using ``torchvision.transforms`` documentation, write code which compose the above transformers.\n",
        "\n",
        "Your transform have to convert a numpy array to tensor of type float32 and multiply the labels of the data by 4. Show your code works. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5TSfEXzipM3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "4d2d1b68-8a2e-42a0-9f2d-485567f9ab6b"
      },
      "source": [
        "### START CODE HERE ### (~12 lines of code)\n",
        "composed = torchvision.transforms.Compose([ToFloat32(), ToTensor(), MulTransform(4)])\n",
        "plt.figure()\n",
        "\n",
        "for transform, title in zip([None, composed], [\"Without transform\", \"With transform\"]):\n",
        "  dataset = LinearData(n_samples=500, transform=transform)\n",
        "  xs , ys = [], []\n",
        "  for i in range(len(dataset)):\n",
        "    xs.append(dataset[i][0].item())\n",
        "    ys.append(dataset[i][1].item())\n",
        "  plt.scatter(xs, ys, label = title)\n",
        "  \n",
        "plt.legend()\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.title(\"Linear dataset\")\n",
        "### END CODE HERE ###  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Linear dataset')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PFQSPImABS5",
        "colab_type": "text"
      },
      "source": [
        "## ✍️ Feed-Forward Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BRD8u16Ilkw",
        "colab_type": "text"
      },
      "source": [
        "In this chapter you will write your first nueral network on your own!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCoAIHTZIwB4",
        "colab_type": "text"
      },
      "source": [
        "In this task we will use the well known MNIST dataset. Remember that this is a multiclass classification problem! \n",
        "\n",
        "Our nueral network will have 1 hidden layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuyGTaAJKTpW",
        "colab_type": "text"
      },
      "source": [
        "At first, let's define some hyper-parameters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TQRxHOieXbb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "09a2e6b2-14c4-4ebd-dc05-5f942f2af485"
      },
      "source": [
        "### Delete this cell with solutions!\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# device = torch.device('cpu')\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pF4N-TlMvl5m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_size = 784 # 28x28\n",
        "hidden_size = 240 \n",
        "num_classes = 10\n",
        "num_epochs = 2\n",
        "batch_size = 100\n",
        "learning_rate = 0.001"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMz8FcVRKfaF",
        "colab_type": "text"
      },
      "source": [
        "Now, we define our dataset and dataloader for both the train and test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nIJqHPsvM5Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369,
          "referenced_widgets": [
            "13ee488ac87d4ca08ca65c52007b9a45",
            "13fb20cbc4ec498cb3647cb8bc5636e6",
            "db1a520d33ec492cafc7c4bef5ac0b4d",
            "e61e6d62807a4d98aa02ec9efce34385",
            "1a1a983a94054905bb11a17b63849a42",
            "7be10f41d44a494d9f7b505defdddecd",
            "c3f755f2031140a58703ca96f2aba0c1",
            "c622970aa21d4950a22211d471ab0c37",
            "c6526d53f38f4e18a2f05d10ed235b71",
            "1e316fe196364204a40b6086aa138042",
            "bf5a42a74d2649819101e76e175be5b0",
            "374216a3626e44b6aaa31635e7e4463f",
            "c6d6eb302b6641639f9e23d1c85e718b",
            "55b895b1eb4540b3b85657182e7b2d3d",
            "e7745844a9d74fd5a9f081921359e78d",
            "c719772f047d4b7dafc1d70a5d24b3f7",
            "058ddde9299f4ad48eb342d6c9ebf8e5",
            "df392a622edf4fddbc3a191df64e0716",
            "1948a4f92b834db3a2815fa21f42d09e",
            "563eee532e3c42a692c7982427b86b45",
            "c623591cb7a14d1eacaedf0e448d0dcb",
            "f7761dd859d44fbbb49e0e42ca1ee8a8",
            "e22d257c1f9f441c85ac955e45747e94",
            "3cf21db7920442a9b00e9fc29b080a7f",
            "c619812fdeb640809c699c56b87198f6",
            "612439a0c2a74fac89324226f1d7ff33",
            "ba16954260ee49d186433e63b60f3757",
            "905c9c03e2fb4e578b485676729e8a74",
            "8468b21b37584ea6a88794352c548154",
            "cb166b52b45f40188d4ff158ff1e9ff4",
            "f4aa2f9b38274399b79e1cde38002e5a",
            "dd1aadb71d6a4025aa1c3c5ef939a66e"
          ]
        },
        "outputId": "6c9ec1e4-cb4f-451c-faed-ceb1e39311ec"
      },
      "source": [
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', \n",
        "                                           train=True, \n",
        "                                          transform=torchvision.transforms.ToTensor(),  \n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', \n",
        "                                          train=False, \n",
        "                                          transform=torchvision.transforms.ToTensor())\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "13ee488ac87d4ca08ca65c52007b9a45",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c6526d53f38f4e18a2f05d10ed235b71",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "058ddde9299f4ad48eb342d6c9ebf8e5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c619812fdeb640809c699c56b87198f6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/pytorch/torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffhQDIHUKtS6",
        "colab_type": "text"
      },
      "source": [
        "✍️ Define your nueral network class. Use ReLU as your activation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mN3Z5pljvdcH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### START CODE HERE ### (~12 lines of code)\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.l1 = nn.Linear(input_size, hidden_size) \n",
        "        self.relu = nn.ReLU()\n",
        "        self.l2 = nn.Linear(hidden_size, num_classes)  \n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.l1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.l2(out)\n",
        "        return out\n",
        "### END CODE HERE ###  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQEJD-QGLJ_G",
        "colab_type": "text"
      },
      "source": [
        "✍️ Initialize your model with the above hyper-parameters. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMICh4D1FAqH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "62856073-f345-43b2-d986-3419b1ab7fa3"
      },
      "source": [
        "### START CODE HERE ### (~1 line of code)\n",
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
        "print(model)\n",
        "### END CODE HERE ###  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NeuralNet(\n",
            "  (l1): Linear(in_features=784, out_features=240, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (l2): Linear(in_features=240, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_ODwLF6Lc8v",
        "colab_type": "text"
      },
      "source": [
        "✍️ Define the loss (which one should you choose? check the documentation and read it deeply! Fix your model definition if needed.) and use SGD as your optimization algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1_cW9A9FBxO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### START CODE HERE ### (2 lines of code)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n",
        "### END CODE HERE ###  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3CyAywlM-Ul",
        "colab_type": "text"
      },
      "source": [
        "✍️ Write the training loop:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOfQgs7_FGkO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "bebb1041-a014-41e2-9c2a-f579955ffdc4"
      },
      "source": [
        "start = time.time()\n",
        "\n",
        "### START CODE HERE ### (~10 lines of code)\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if (i+1) % 100 == 0:\n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
        "### END CODE HERE ### \n",
        "\n",
        "end = time.time()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/2], Step [100/600], Loss: 2.2871\n",
            "Epoch [1/2], Step [200/600], Loss: 2.2589\n",
            "Epoch [1/2], Step [300/600], Loss: 2.2573\n",
            "Epoch [1/2], Step [400/600], Loss: 2.2217\n",
            "Epoch [1/2], Step [500/600], Loss: 2.1943\n",
            "Epoch [1/2], Step [600/600], Loss: 2.1786\n",
            "Epoch [2/2], Step [100/600], Loss: 2.1693\n",
            "Epoch [2/2], Step [200/600], Loss: 2.1516\n",
            "Epoch [2/2], Step [300/600], Loss: 2.1197\n",
            "Epoch [2/2], Step [400/600], Loss: 2.0858\n",
            "Epoch [2/2], Step [500/600], Loss: 2.0703\n",
            "Epoch [2/2], Step [600/600], Loss: 2.0471\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6M2t9uLXTicx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3fbf8587-8fd1-4f0d-fd42-2e4bfca6f4f5"
      },
      "source": [
        "print(f\"Training took {end-start} seconds.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training took 14.020952701568604 seconds.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgLL8cXKNR4y",
        "colab_type": "text"
      },
      "source": [
        "✍️ Test your model on the test data. \n",
        "\n",
        "Make sure you don't waste time computing things you don't need! \n",
        "\n",
        "What is your accuracy?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnpRDSeDz4Qw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5f59373e-f40b-4b5c-ad65-22181b45d175"
      },
      "source": [
        "### START CODE HERE ### (~10 lines of code)\n",
        "with torch.no_grad():\n",
        "    n_correct, n_samples = 0, 0\n",
        "    for images, labels in test_loader:\n",
        "\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "      \n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network on the test images: {acc} %')\n",
        "### END CODE HERE ### "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the test images: 67.44 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sNoppkeNoz_",
        "colab_type": "text"
      },
      "source": [
        "Our accuracy is much better than a random guess, however, we want to improve it!\n",
        "\n",
        "In order to improve our model preformence we should check whether our model overfits the data or try different hyper-parmeters.\n",
        "\n",
        "In order to check if our model overfits the data we can plot the loss of the training and the validation as function of the epoch number.\n",
        "We will not get into it now, but you will do it in your next exercices!\n",
        "\n",
        "So, now we will try different hyper-parameters in order to achieve better preformance.\n",
        "However, training took too much time! We must use our resources wisely!\n",
        "In the next chapter we will learn how to use the gpu!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ql8lYhQbP4L6",
        "colab_type": "text"
      },
      "source": [
        "## Using the GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNM-yUGYZMzI",
        "colab_type": "text"
      },
      "source": [
        "By default all tensors are created on the CPU,\n",
        "but you can also move them to the GPU (if it's available)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mxvlKWFP4aW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d3edb219-76bd-4d3b-9e16-fc2fcf0c1903"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzXMzvSbapzb",
        "colab_type": "text"
      },
      "source": [
        "You can directly create a tensor on GPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35NiTndkZ95P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "5e54a6c8-cb9c-437b-c765-04d6d4902895"
      },
      "source": [
        "x = torch.rand(5,3) \n",
        "print(x, \"\\n\")\n",
        "y = torch.ones_like(x, device=device)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.6313, 0.4472, 0.1248],\n",
            "        [0.0708, 0.9416, 0.5002],\n",
            "        [0.0851, 0.3349, 0.7646],\n",
            "        [0.0610, 0.6704, 0.3565],\n",
            "        [0.3718, 0.3864, 0.4334]]) \n",
            "\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qno4hdqla014",
        "colab_type": "text"
      },
      "source": [
        "Or you can just move it to the GPU. \n",
        "\n",
        "Additional option to indicate device is to use strings ``.to(\"cuda\")``"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpVBH4s9Z-CO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "9fe2d373-5ecb-4ddc-f646-3dfdc0b871b9"
      },
      "source": [
        "x = x.to(device)\n",
        "print(x)                      "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.6313, 0.4472, 0.1248],\n",
            "        [0.0708, 0.9416, 0.5002],\n",
            "        [0.0851, 0.3349, 0.7646],\n",
            "        [0.0610, 0.6704, 0.3565],\n",
            "        [0.3718, 0.3864, 0.4334]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JVsJlffbO2g",
        "colab_type": "text"
      },
      "source": [
        "It's not possible to convert tensor which is on the GPU to a numpy array because numpy cannot handle GPU tenors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UHHQDBkbDwX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "cd6ee01f-29d6-4453-f1e7-f72300d0a404"
      },
      "source": [
        "z = x + y\n",
        "print(z)\n",
        "z = z.numpy() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1.6695, 1.8345, 1.0992],\n",
            "        [1.8004, 1.1962, 1.5636],\n",
            "        [1.6748, 1.2561, 1.2609],\n",
            "        [1.0433, 1.3035, 1.5907],\n",
            "        [1.7153, 1.7089, 1.5687]], device='cuda:0')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-108-5ced6703f81b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M89kdQ1vcTzl",
        "colab_type": "text"
      },
      "source": [
        "You have to move the tensor to the CPU and then convert it to a numpy array.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mURj8_DcbL9Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "8b37e8c5-8c7e-4be7-d1a2-64f2dd0e717f"
      },
      "source": [
        "z = z.to(\"cpu\")       \n",
        "z = z.numpy()\n",
        "print(z)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.6695204 1.8344823 1.099164 ]\n",
            " [1.8003998 1.1962361 1.5636164]\n",
            " [1.6748052 1.2561101 1.2609254]\n",
            " [1.0432749 1.303493  1.590729 ]\n",
            " [1.7152858 1.7089095 1.5686543]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tl_9etX3nR9K",
        "colab_type": "text"
      },
      "source": [
        "Now, after you have learnt how to run tensors on the GPU let's try it!\n",
        "\n",
        "✍️ Try to run your model from the previous chapter on the GPU.\n",
        "In order to make it you have to move any inputs/tensors and your model to the GPU.\n",
        "\n",
        "Did your time performance got better?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEKIgsEAvST-",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "Probably, your answer is no.\n",
        "\n",
        "This can happen when the cost of transferring data between RAM and GPU memory is more than the speedup of parallel computation on the GPU.\n",
        "\n",
        "It can happen when your model is quite small, or in case when you have too many transfers of data in your forward() function.\n",
        "\n",
        "If you still want to see improvment in the time preformance, increase the number of epochs and use only 1 batch (batch = all your dataset) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sE06VviAKiR",
        "colab_type": "text"
      },
      "source": [
        "## RNNs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQljClGBJjZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}